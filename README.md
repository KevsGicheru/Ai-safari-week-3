<!DOCTYPE html>
<html>
  <head>
    <title>Hello, World!</title>
    <link rel="stylesheet" href="styles.css" />
  </head>
  <body>
      <h1 class="title"> AI SAFARI ASSIGNMENT </h1>
      <br>
        <h2 style="color:blue;">üïµÔ∏è‚Äç‚ôÄÔ∏èAI Inspector's Report: Case 1 - The Hiring Bo</h2>
<p> As an AI inspector, I'm here to check out how companies are using AI. The first case is of a company using a bot to hire people. </p>
<p><h3> A.	What's happening?</h3>
This company uses an AI bot to screen job applicants. The bot reads through all the CVs, or resumes, and picks out the best ones for the hiring manager to look at. It's like a super-fast assistant that filters a huge pile of papers in seconds. The AI learns from past successful employees to decide what a "good" candidate looks like.
<br>
<h4> B.	What's problematic? </h4>
My investigation found a big problem. The bot is being unfair! It tends to reject more female applicants with career gaps. Why? Because the AI was trained on data from previous employees, most of whom were men who didn't take time off. The AI thinks that having a continuous career is the only good thing. This means it's ignoring brilliant women who took time off for things like raising a family or personal growth. It's a classic case of bias, and it's not fair to the applicants. This bot is creating an uneven playing field.
<br>

<h4> C.	One improvement idea</h4>
We can fix this. The company should retrain the AI with a more diverse dataset. This means including CVs of successful employees from all genders, including those with career gaps. They can also tell the AI to ignore career gaps as a negative factor and focus on skills and experience instead. This way, the bot will learn to value all types of work histories and give everyone a fair chance.</p>
<br>


 <h1 style="color:blue;">Case 2 - The School Proctoring AI</h1>
 
 
Next up, is a case of a school that's using AI to monitor students during exams. They say it's to prevent cheating, but is it doing more harm than good? Let's find out!
<p><h2> A.	What's happening?</h2>
  

The school has an AI proctoring system. It uses a student's webcam to watch them during an online exam. The AI tracks things like eye movement and whether the student is looking away from the screen. If it detects suspicious behavior, it flags the student as potentially cheating. It's like a teacher who can watch every student at the same time.
<br>
<h3>B.	What's problematic? </h3>
Here's the issue: the AI is unfairly flagging neurodivergent students. These are students with conditions like ADHD or autism. For example, a student with ADHD might have trouble keeping their eyes still or might fidget a lot. The AI sees this as "cheating," but it's just how their brain works. This system is causing unnecessary stress and can lead to students being wrongly accused. It‚Äôs a problem of fairness and accessibility.
<br>
<h4> C.	One improvement idea </h4>
We need to change how this AI works. Instead of the AI automatically flagging a student as a cheater, it should just send a report to a human teacher. The teacher can then review the video footage and decide what's happening. This makes the human the final decision-maker. It also gives students a chance to explain themselves. This way, we use the AI as a tool to help, not as a judge that unfairly punishes students.

</p> 
  </body>
  <br>
  
  <footer><sub>Written by Kelvin</footer>
</html>
